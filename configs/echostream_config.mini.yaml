# EchoStream Configuration (Mini)
# Smaller model focused on unit learning stability and lower memory/latency

model_name: echostream_mini
model_type: speech_to_speech

# ============================================
# Encoder: Emformer (Mini)
# ============================================
encoder:
  type: emformer
  embed_dim: 128
  layers: 4
  attention_heads: 2
  ffn_embed_dim: 512

  # Emformer-specific parameters
  segment_length: 4            # 40ms @ 100fps (4 frames)
  left_context_length: 30      # 300ms context (30 frames)
  right_context_length: 0      # Full streaming (no lookahead)
  memory_size: 8               # Memory bank size

  # Input
  input_feat_per_channel: 80   # Filter-bank features
  input_channels: 1

# ============================================
# Decoders (Mini)
# ============================================

# ASR CTC Decoder (lightweight, for punctuation/anchors)
asr_decoder:
  type: ctc
  embed_dim: 128
  vocab_size: 6000

# ST CTC Decoder (lightweight streaming)
st_decoder:
  type: ctc_with_transformer
  embed_dim: 128
  layers: 1
  attention_heads: 2
  vocab_size: 6000
  unidirectional: true

# MT Decoder (smaller)
mt_decoder:
  type: transformer
  embed_dim: 128
  layers: 2
  attention_heads: 2
  ffn_embed_dim: 512
  vocab_size: 6000

# Unit Decoder (focus on stability)
unit_decoder:
  type: ctc_transformer_unit
  embed_dim: 128
  layers: 2
  attention_heads: 2
  ffn_embed_dim: 512
  num_units: 1000        # HuBERT units
  ctc_upsample_ratio: 5

# ============================================
# Vocoder
# ============================================
vocoder:
  type: codehifigan
  use_vocoder: false  # Disable during training for stability/speed; enable at inference
  checkpoint_path: /Users/hayubin/EchoStream/pretrain_models/unit-based_HiFi-GAN_vocoder/mHuBERT.layer11.km1000.en/g_00500000
  config_path: /Users/hayubin/EchoStream/pretrain_models/unit-based_HiFi-GAN_vocoder/mHuBERT.layer11.km1000.en/config.json

# ============================================
# Training (Mini)
# ============================================
training:
  max_epochs: 50
  batch_size: 8
  max_tokens: 20000
  update_freq: 4

  # Optimizer
  optimizer: adam
  lr: 0.0003
  adam_betas: [0.9, 0.98]
  adam_eps: 1.0e-08
  weight_decay: 0.0001

  # LR schedule
  lr_scheduler: inverse_sqrt
  warmup_updates: 800
  warmup_init_lr: 1.0e-07

  # Regularization (slightly higher dropout for small model)
  dropout: 0.2
  attention_dropout: 0.2
  activation_dropout: 0.2
  label_smoothing: 0.1

  # Gradient clipping
  clip_norm: 1.0

# ============================================
# Multi-task Learning (emphasize units)
# ============================================
multitask:
  # Task weights (focus on Unit)
  asr_weight: 0.05
  st_weight: 0.05
  mt_weight: 0.20
  unit_weight: 0.70

  # CTC mixing
  ctc_weight: 0.5

# ============================================
# Streaming / Inference
# ============================================
streaming:
  chunk_size: 40         # ms (alias: chunk_size_ms is also supported)
  wait_k: 5
  ctc_threshold: 0.6     # slightly stricter gating for stability
  enable_punctuation: true
  ct_transformer_path: pretrain_models/ct_transformer.onnx

# ============================================
# Data
# ============================================
data:
  data_root: ../data
  train_manifest: ../data/train_sampled.tsv
  valid_manifest: ../data/dev_sampled.tsv
  test_manifest: ../data/test_sampled.tsv
  units_root: /Users/hayubin/EchoStream/data/units

  # Preprocessing
  use_audio_input: true
  num_mel_bins: 80
  sample_rate: 16000
  load_tgt_units: true   # ensure unit targets are loaded

  # Global CMVN
  global_cmvn_stats_npz: /Users/hayubin/EchoStream/data/gcmvn.npz

  # Dictionaries
  src_dict: /Users/hayubin/EchoStream/data/src_unigram6000/spm_unigram_ko.txt
  tgt_dict: /Users/hayubin/EchoStream/data/tgt_unigram6000/spm_unigram_en.txt

  # HuBERT units
  hubert_model: /Users/hayubin/EchoStream/pretrain_models/mHuBERT/mhubert_base_vp_en_es_fr_it3_L11_km1000.bin
  hubert_layer: 11
  num_clusters: 1000

# ============================================
# Evaluation
# ============================================
evaluation:
  compute_bleu: true
  compute_asr_bleu: true
  compute_latency: true
  latency_metrics: [AL, AP, DAL]
  target_latency_al: 1000

# ============================================
# Hardware
# ============================================
hardware:
  num_gpus: 1
  fp16: true
  distributed_world_size: 1


