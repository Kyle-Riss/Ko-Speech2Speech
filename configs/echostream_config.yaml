# EchoStream Configuration
# Efficient Memory-based Streaming Speech-to-Speech Translation

model_name: echostream
model_type: speech_to_speech

# ============================================
# Encoder: Emformer
# ============================================
encoder:
  type: emformer
  embed_dim: 256
  layers: 16
  attention_heads: 4
  ffn_embed_dim: 1024
  
  # Emformer-specific parameters
  segment_length: 4           # 40ms @ 100fps (4 frames)
  left_context_length: 30     # 300ms context (30 frames)
  right_context_length: 0     # Full streaming (no lookahead)
  memory_size: 8              # Memory bank size
  
  # Input
  input_feat_per_channel: 80  # Filter-bank features
  input_channels: 1

# ============================================
# Decoders
# ============================================

# ASR CTC Decoder (for punctuation prediction)
asr_decoder:
  type: ctc
  embed_dim: 256
  vocab_size: 6000  # Source language unigram

# ST CTC Decoder (for translation)
st_decoder:
  type: ctc_with_transformer
  embed_dim: 256
  layers: 2
  attention_heads: 4
  vocab_size: 6000  # Target language unigram
  unidirectional: true  # For streaming

# MT Decoder (for text refinement)
mt_decoder:
  type: transformer
  embed_dim: 256
  layers: 4
  attention_heads: 4
  ffn_embed_dim: 1024
  vocab_size: 6000

# Unit Decoder (for speech unit generation)
unit_decoder:
  type: ctc_transformer_unit
  embed_dim: 256
  layers: 6
  attention_heads: 4
  ffn_embed_dim: 1024
  num_units: 1000  # HuBERT units
  ctc_upsample_ratio: 5

# Vocoder (CodeHiFiGAN)
vocoder:
  type: codehifigan
  checkpoint_path: pretrain_models/vocoder_checkpoint.pt
  config_path: pretrain_models/vocoder_config.json

# ============================================
# Training
# ============================================
training:
  max_epochs: 100
  batch_size: 16
  max_tokens: 40000
  update_freq: 4
  
  # Optimizer
  optimizer: adam
  lr: 0.0005
  adam_betas: [0.9, 0.98]
  adam_eps: 1.0e-08
  weight_decay: 0.0001
  
  # Learning rate schedule
  lr_scheduler: inverse_sqrt
  warmup_updates: 10000
  warmup_init_lr: 1.0e-07
  
  # Regularization
  dropout: 0.1
  attention_dropout: 0.1
  activation_dropout: 0.1
  label_smoothing: 0.1
  
  # Gradient clipping
  clip_norm: 10.0

# ============================================
# Multi-task Learning
# ============================================
multitask:
  # Task weights
  asr_weight: 0.3
  st_weight: 0.3
  mt_weight: 0.2
  unit_weight: 0.2
  
  # CTC weights
  ctc_weight: 0.5

# ============================================
# Streaming / Inference
# ============================================
streaming:
  # Chunk processing
  chunk_size: 40  # ms
  
  # Wait-k policy (for comparison)
  wait_k: 5
  
  # CTC policy threshold
  ctc_threshold: 0.5
  
  # Punctuation-based recomposition
  enable_punctuation: true
  ct_transformer_path: pretrain_models/ct_transformer.onnx

# ============================================
# Data
# ============================================
data:
  train_manifest: data/train.tsv
  valid_manifest: data/valid.tsv
  test_manifest: data/test.tsv
  
  # Preprocessing
  use_audio_input: true
  num_mel_bins: 80
  sample_rate: 16000
  
  # Global CMVN
  global_cmvn_stats_npz: data/gcmvn.npz
  
  # Dictionaries
  src_dict: data/src_unigram6000.txt
  tgt_dict: data/tgt_unigram6000.txt
  
  # HuBERT units
  hubert_model: pretrain_models/mhubert.km1000.layer11.pt
  hubert_layer: 11
  num_clusters: 1000

# ============================================
# Evaluation
# ============================================
evaluation:
  # Metrics
  compute_bleu: true
  compute_asr_bleu: true
  
  # Latency metrics (SimulEval)
  compute_latency: true
  latency_metrics: [AL, AP, DAL]
  
  # Quality vs Latency
  target_latency_al: 1000  # ms

# ============================================
# Hardware
# ============================================
hardware:
  num_gpus: 1
  fp16: true
  distributed_world_size: 1

