# Mac M2 8GB RAM νμΈνλ‹ κ°€μ΄λ“

**ν™κ²½**: Mac M2, RAM 8GB  
**λ©μ **: λ©”λ¨λ¦¬ μ μ•½ ν™κ²½μ—μ„ μ•μ •μ μΈ νμΈνλ‹

---

## π― ν•µμ‹¬ μ „λµ

### 1. μ‘μ€ λ¨λΈ ν¬κΈ°
- Encoder: 4 layers (κΈ°μ΅΄ 16 β†’ 4)
- Embed dim: 128 (κΈ°μ΅΄ 256 β†’ 128)
- Attention heads: 2 (κΈ°μ΅΄ 4 β†’ 2)
- FFN dim: 512 (κΈ°μ΅΄ 1024 β†’ 512)

### 2. μ‘μ€ λ°°μΉ μ‚¬μ΄μ¦ + Gradient Accumulation
- Batch size: 2 (λ§¤μ° μ‘μ)
- Update freq: 8 (gradient accumulation)
- **Effective batch size**: 2 Γ— 8 = 16

### 3. λ©”λ¨λ¦¬ μµμ ν™” μ„¤μ •
- `num_workers: 0` (Mac multiprocessing μ΄μ λ°©μ§€)
- `pin_memory: false` (CPU μ‚¬μ© μ‹ λ¶ν•„μ”)
- `fp16: false` (Macμ—μ„ μ•μ •μ„±)

---

## π“‹ μ„¤μ • νμΌ

### Mac M2 8GB μ „μ© Config

**νμΌ**: `configs/echostream_config.mac_m2_8gb.yaml`

μ£Όμ” μ„¤μ •:
```yaml
encoder:
  embed_dim: 128      # μ‘μ€ μ„λ² λ”©
  layers: 4           # μ μ€ λ μ΄μ–΄
  attention_heads: 2
  ffn_embed_dim: 512

training:
  batch_size: 2       # λ§¤μ° μ‘μ€ λ°°μΉ
  update_freq: 8      # Gradient accumulation
  max_tokens: 5000    # μ‘μ€ ν† ν° μ

hardware:
  num_workers: 0      # Mac multiprocessing λ°©μ§€
  fp16: false         # μ•μ •μ„±
  pin_memory: false
```

---

## π€ νμΈνλ‹ μ‹¤ν–‰ λ°©λ²•

### 1. κΈ°μ΅΄ μ²΄ν¬ν¬μΈνΈμ—μ„ μ΄μ–΄μ„ ν•™μµ (Resume)

**ν„μ¬ μƒν™©**: μ΄λ―Έ Emformer κΈ°λ° μ²΄ν¬ν¬μΈνΈκ°€ μμ
- `checkpoints_mini_units_v4/checkpoint_best.pt` (Epoch 9)

**μ¶”κ°€ ν•™μµ λ°©λ²•**:

```bash
# Mac M2 8GB μµμ ν™” μ„¤μ •μΌλ΅ νμΈνλ‹
python scripts/train.py \
  --config configs/echostream_config.mac_m2_8gb.yaml \
  --train-manifest data/train_sampled.units.tsv \
  --dev-manifest data/dev_sampled.units.tsv \
  --save-dir checkpoints_mini_units_v5 \
  --num-workers 0 \
  --batch-size 2 \
  --epochs 50
```

**μ£Όμμ‚¬ν•­**:
- ν„μ¬ `train.py`μ—λ” resume κΈ°λ¥μ΄ μ—†μ
- κΈ°μ΅΄ μ²΄ν¬ν¬μΈνΈλ¥Ό λ΅λ“ν•λ ¤λ©΄ μ½”λ“ μμ • ν•„μ”

---

### 2. μ²μλ¶€ν„° ν•™μµ (κ¶μ¥)

**μ΄μ **: Mac M2 8GBμ—μ„λ” μ‘μ€ λ¨λΈλ΅ μ²μλ¶€ν„° ν•™μµν•λ” κ²ƒμ΄ μ•μ •μ 

```bash
# Mac M2 8GB μµμ ν™” μ„¤μ •
python scripts/train.py \
  --config configs/echostream_config.mac_m2_8gb.yaml \
  --train-manifest data/train_sampled.units.tsv \
  --dev-manifest data/dev_sampled.units.tsv \
  --save-dir checkpoints_mac_m2_8gb \
  --num-workers 0 \
  --epochs 50
```

---

## π’Ύ λ©”λ¨λ¦¬ μ‚¬μ©λ‰ μμƒ

### λ¨λΈ ν¬κΈ° (Mac M2 μ„¤μ •)

```
Encoder (4L, 128d):      ~2.5M parameters
ASR CTC:                 ~0.8M
ST CTC (1L):             ~0.3M
MT Decoder (2L):         ~1.0M
Unit Decoder (2L):       ~1.2M
Total:                   ~5.8M parameters (~22 MB @ fp32)
```

### ν•™μµ μ‹ λ©”λ¨λ¦¬

```
λ¨λΈ:            ~22 MB
Gradients:       ~22 MB
Optimizer state: ~44 MB (Adam)
Batch (size=2):  ~50 MB
Total:           ~138 MB (μ•μ „!)
```

**8GB RAMμ—μ„ μ¶©λ¶„ν μ—¬μ  μμ!**

---

## β™οΈ Gradient Accumulation λ™μ‘

### μ‘λ™ μ›λ¦¬

```python
# update_freq = 8μΌ λ•
for batch in dataloader:
    loss = model(batch) / 8  # Loss μ¤μΌ€μΌλ§
    loss.backward()          # Gradient λ„μ 
    
    if accumulated_batches >= 8:
        optimizer.step()    # 8κ° λ°°μΉ λ„μ  ν›„ μ—…λ°μ΄νΈ
        optimizer.zero_grad()
```

### ν¨κ³Ό

- **λ©”λ¨λ¦¬**: λ°°μΉ μ‚¬μ΄μ¦ 2λ§ μ‚¬μ© (λ©”λ¨λ¦¬ μ μ•½)
- **ν•™μµ ν¨κ³Ό**: Effective batch size = 16 (ν° λ°°μΉμ™€ λ™μΌ)
- **μ•μ •μ„±**: μ‘μ€ λ°°μΉλ΅ λ©”λ¨λ¦¬ μ¤λ²„ν”λ΅μ° λ°©μ§€

---

## π”§ μ¶”κ°€ μµμ ν™” ν

### 1. λ°μ΄ν„° λ΅λ”© μµμ ν™”

```yaml
# configs/echostream_config.mac_m2_8gb.yaml
hardware:
  num_workers: 0  # Macμ—μ„ ν•„μ (multiprocessing μ΄μ)
```

### 2. μ§§μ€ λ°ν™”λ§ μ‚¬μ©

```yaml
data:
  max_duration: 10.0  # 10μ΄ μ΄ν•λ§ μ‚¬μ© (λ©”λ¨λ¦¬ μ μ•½)
```

### 3. μ²΄ν¬ν¬μΈνΈ μ €μ¥ κ°„κ²© μ΅°μ •

```bash
# μμ£Ό μ €μ¥ν•μ§€ μ•κΈ° (λ””μ¤ν¬ I/O κ°μ†)
--save-interval 20  # 20 epochλ§λ‹¤ μ €μ¥
```

### 4. Mixed Precision λΉ„ν™μ„±ν™”

```yaml
hardware:
  fp16: false  # Mac M2μ—μ„ μ•μ •μ„± μ°μ„ 
```

---

## π“ μμƒ ν•™μµ μ‹κ°„

### Mac M2 8GB ν™κ²½

```
λ¨λΈ ν¬κΈ°: 5.8M parameters
λ°°μΉ μ‚¬μ΄μ¦: 2
Update freq: 8
Effective batch: 16

μμƒ μ†λ„:
- 1 epoch: ~30-60λ¶„ (λ°μ΄ν„° ν¬κΈ°μ— λ”°λΌ)
- 50 epochs: ~25-50μ‹κ°„
```

**κ¶μ¥**: λ°¤μƒ ν•™μµ λλ” λ°±κ·ΈλΌμ΄λ“ μ‹¤ν–‰

---

## β… μ²΄ν¬λ¦¬μ¤νΈ

ν•™μµ μ‹μ‘ μ „:

- [x] soundfile μ„¤μΉ μ™„λ£
- [ ] Config νμΌ ν™•μΈ (`echostream_config.mac_m2_8gb.yaml`)
- [ ] λ°μ΄ν„° κ²½λ΅ ν™•μΈ
- [ ] Units νμΌ μ΅΄μ¬ ν™•μΈ
- [ ] λ©”λ¨λ¦¬ μ—¬μ  κ³µκ°„ ν™•μΈ (μµμ† 2GB)
- [ ] λ°°μΉ μ‚¬μ΄μ¦ ν™•μΈ (2)
- [ ] Update freq ν™•μΈ (8)
- [ ] num_workers ν™•μΈ (0)

---

## π¨ λ¬Έμ  ν•΄κ²°

### λ©”λ¨λ¦¬ λ¶€μ΅± μ¤λ¥

```
RuntimeError: CUDA out of memory
β†’ Mac M2λ” CPU μ‚¬μ©, μ΄ μ¤λ¥λ” λ°μƒν•μ§€ μ•μ

OSError: [Errno 12] Cannot allocate memory
β†’ λ°°μΉ μ‚¬μ΄μ¦λ¥Ό 1λ΅ μ¤„μ΄κΈ°
β†’ update_freqλ¥Ό 16μΌλ΅ λλ¦¬κΈ°
```

### ν•΄κ²° λ°©λ²•

```yaml
# λ” μ‘μ€ μ„¤μ •
training:
  batch_size: 1       # 2 β†’ 1
  update_freq: 16     # 8 β†’ 16 (effective batch μ μ§€)
  max_tokens: 3000    # 5000 β†’ 3000
```

---

## π― μµμΆ… κ¶μ¥ μ‚¬ν•­

### Mac M2 8GB ν™κ²½

1. **μ‘μ€ λ¨λΈ μ‚¬μ©**: `echostream_config.mac_m2_8gb.yaml`
2. **μ‘μ€ λ°°μΉ + Accumulation**: batch_size=2, update_freq=8
3. **CPU μ‚¬μ©**: GPU μ—†μ΄λ„ μ¶©λ¶„ν λΉ λ¦„ (M2 Neural Engine ν™μ©)
4. **μ•μ •μ„± μ°μ„ **: fp16 λΉ„ν™μ„±ν™”, num_workers=0

### μ‹¤ν–‰ λ…λ Ήμ–΄

```bash
# μµμΆ… κ¶μ¥ λ…λ Ήμ–΄
python scripts/train.py \
  --config configs/echostream_config.mac_m2_8gb.yaml \
  --train-manifest data/train_sampled.units.tsv \
  --dev-manifest data/dev_sampled.units.tsv \
  --save-dir checkpoints_mac_m2_8gb \
  --num-workers 0 \
  --epochs 50
```

---

**μ¤€λΉ„ μ™„λ£!** Mac M2 8GB ν™κ²½μ—μ„ μ•μ •μ μΌλ΅ νμΈνλ‹ν•  μ μμµλ‹λ‹¤! π€

---

**λ§μ§€λ§‰ μ—…λ°μ΄νΈ**: 2025-01-XX  
**λ²„μ „**: 1.0

