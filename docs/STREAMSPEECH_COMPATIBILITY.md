# StreamSpeech í˜¸í™˜ì„± ê°€ì´ë“œ

**ì¤‘ìš”**: EchoStreamì€ StreamSpeechì˜ ë””ì½”ë” êµ¬ì¡°ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ, **ë°˜ë“œì‹œ StreamSpeech/Fairseq í˜•ì‹ì„ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤**. í˜•ì‹ì„ ë§ì¶”ì§€ ì•Šìœ¼ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤.

---

## ğŸ”´ í•„ìˆ˜ êµ¬ì¡°: Encoder ì¶œë ¥ í˜•ì‹

### ì˜¬ë°”ë¥¸ í˜•ì‹ (StreamSpeech/Fairseq í˜¸í™˜)

```python
encoder_out = {
    'encoder_out': [tensor],              # âš ï¸ List í˜•íƒœ! [T, B, D]
    'encoder_padding_mask': [tensor],    # âš ï¸ List í˜•íƒœ! [B, T] ë˜ëŠ” []
    'encoder_embedding': [],              # ë¹ˆ ë¦¬ìŠ¤íŠ¸
    'encoder_states': [],                 # ë¹ˆ ë¦¬ìŠ¤íŠ¸
    'src_tokens': [],                     # ë¹ˆ ë¦¬ìŠ¤íŠ¸
    'src_lengths': [],                   # ë¹ˆ ë¦¬ìŠ¤íŠ¸
}
```

### âŒ ì˜ëª»ëœ í˜•ì‹ (ì˜¤ë¥˜ ë°œìƒ!)

```python
# ì˜ëª»ëœ ì˜ˆ 1: Listê°€ ì•„ë‹Œ ì§ì ‘ í…ì„œ
encoder_out = {
    'encoder_out': tensor,  # âŒ Listê°€ ì•„ë‹˜!
    ...
}

# ì˜ëª»ëœ ì˜ˆ 2: ì°¨ì› ìˆœì„œê°€ ë‹¤ë¦„
encoder_out = {
    'encoder_out': [tensor],  # âŒ [B, T, D] (time-firstê°€ ì•„ë‹˜!)
    ...
}

# ì˜ëª»ëœ ì˜ˆ 3: í‚¤ ì´ë¦„ì´ ë‹¤ë¦„
encoder_out = {
    'output': [tensor],  # âŒ 'encoder_out'ì´ ì•„ë‹˜!
    ...
}
```

---

## ğŸ“ í…ì„œ ì°¨ì› ìˆœì„œ

### Encoder ì¶œë ¥

```python
encoder_out['encoder_out'][0]  # [T, B, D]
# T: ì‹œê°„ í”„ë ˆì„ (ë‹¤ìš´ìƒ˜í”Œë§ í›„)
# B: ë°°ì¹˜ í¬ê¸°
# D: ì„ë² ë”© ì°¨ì› (ì˜ˆ: 256)
```

**ì¤‘ìš”**: 
- âœ… **Time-first**: `[T, B, D]` í˜•ì‹
- âŒ Batch-first: `[B, T, D]` í˜•ì‹ (ì˜¤ë¥˜!)

### Padding Mask

```python
encoder_out['encoder_padding_mask'][0]  # [B, T]
# B: ë°°ì¹˜ í¬ê¸°
# T: ì‹œê°„ í”„ë ˆì„
# ê°’: True = padding, False = valid
```

---

## ğŸ”§ ë””ì½”ë”ê°€ ê¸°ëŒ€í•˜ëŠ” í˜•ì‹

### MT Decoder (TransformerMTDecoder)

```python
# models/decoders/transformer_decoder.py
def forward(self, prev_output_tokens, encoder_out):
    # ë””ì½”ë”ëŠ” ì´ë ‡ê²Œ ì ‘ê·¼í•©ë‹ˆë‹¤:
    encoder_hidden = encoder_out['encoder_out'][0]  # [T', B, D]
    if encoder_out['encoder_padding_mask']:
        encoder_padding_mask = encoder_out['encoder_padding_mask'][0]  # [B, T']
```

**ì˜¤ë¥˜ ì˜ˆì‹œ**:
```python
# âŒ ì´ë ‡ê²Œ í•˜ë©´ ì˜¤ë¥˜!
encoder_hidden = encoder_out['encoder_out']  # List ì „ì²´ë¥¼ ì „ë‹¬
# â†’ TypeError: expected Tensor, got list

# âŒ ì´ë ‡ê²Œ í•´ë„ ì˜¤ë¥˜!
encoder_hidden = encoder_out['output']  # í‚¤ ì´ë¦„ì´ ë‹¤ë¦„
# â†’ KeyError: 'output'
```

### CTC Decoder

```python
# models/decoders/ctc_decoder.py
def forward(self, encoder_out, encoder_padding_mask):
    # encoder_out: [T, B, D] í…ì„œ (Listê°€ ì•„ë‹˜!)
    # encoder_padding_mask: [B, T] í…ì„œ ë˜ëŠ” None
```

**ì‚¬ìš© ì˜ˆì‹œ**:
```python
# âœ… ì˜¬ë°”ë¥¸ ì‚¬ìš©
encoder_out_dict = encoder(src_tokens, src_lengths)
encoder_hidden = encoder_out_dict['encoder_out'][0]  # [T, B, D]
encoder_padding_mask = encoder_out_dict['encoder_padding_mask'][0] if encoder_out_dict['encoder_padding_mask'] else None

ctc_output = ctc_decoder(
    encoder_out=encoder_hidden,  # í…ì„œ ì§ì ‘ ì „ë‹¬
    encoder_padding_mask=encoder_padding_mask,
)
```

---

## âœ… ì˜¬ë°”ë¥¸ êµ¬í˜„ ì˜ˆì‹œ

### EchoStreamSpeechEncoder

```python
# models/echostream_encoder.py
class EchoStreamSpeechEncoder(nn.Module):
    def forward(self, src_tokens, src_lengths):
        # ... ì¸ì½”ë”© ë¡œì§ ...
        
        # âœ… ì˜¬ë°”ë¥¸ í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
        return {
            'encoder_out': emformer_out['encoder_out'],  # List of [T, B, D]
            'encoder_padding_mask': emformer_out['encoder_padding_mask'],  # List of [B, T]
            'encoder_embedding': [],
            'encoder_states': [],
            'src_tokens': [],
            'src_lengths': [],
        }
```

### EchoStreamModelì—ì„œ ì‚¬ìš©

```python
# models/echostream_model.py
def forward(self, src_tokens, src_lengths):
    # 1. Encoder í˜¸ì¶œ
    encoder_out = self.encoder(src_tokens, src_lengths)
    
    # 2. âœ… Listì—ì„œ ì²« ë²ˆì§¸ ìš”ì†Œ ì¶”ì¶œ
    encoder_hidden = encoder_out['encoder_out'][0]  # [T', B, D]
    
    # 3. âœ… Padding mask ì¶”ì¶œ (ìˆì„ ê²½ìš°)
    encoder_padding_mask = (
        encoder_out['encoder_padding_mask'][0] 
        if encoder_out['encoder_padding_mask'] 
        else None
    )
    
    # 4. ë””ì½”ë”ì— ì „ë‹¬
    asr_out = self.asr_ctc_decoder(
        encoder_out=encoder_hidden,  # í…ì„œ ì§ì ‘ ì „ë‹¬
        encoder_padding_mask=encoder_padding_mask,
    )
```

---

## ğŸš¨ ìì£¼ ë°œìƒí•˜ëŠ” ì˜¤ë¥˜

### ì˜¤ë¥˜ 1: List ì¸ë±ì‹± ëˆ„ë½

```python
# âŒ ì˜ëª»ëœ ì½”ë“œ
encoder_hidden = encoder_out['encoder_out']  # List ì „ì²´
ctc_decoder(encoder_out=encoder_hidden)  # TypeError!

# âœ… ì˜¬ë°”ë¥¸ ì½”ë“œ
encoder_hidden = encoder_out['encoder_out'][0]  # ì²« ë²ˆì§¸ ìš”ì†Œ
ctc_decoder(encoder_out=encoder_hidden)
```

### ì˜¤ë¥˜ 2: ì°¨ì› ìˆœì„œ ë¶ˆì¼ì¹˜

```python
# âŒ ì˜ëª»ëœ ì½”ë“œ (Batch-first)
encoder_out = {
    'encoder_out': [tensor],  # [B, T, D] í˜•ì‹
}

# âœ… ì˜¬ë°”ë¥¸ ì½”ë“œ (Time-first)
encoder_out = {
    'encoder_out': [tensor],  # [T, B, D] í˜•ì‹
}
```

### ì˜¤ë¥˜ 3: Padding mask ì²˜ë¦¬

```python
# âŒ ì˜ëª»ëœ ì½”ë“œ
encoder_padding_mask = encoder_out['encoder_padding_mask']  # List ì „ì²´

# âœ… ì˜¬ë°”ë¥¸ ì½”ë“œ
if encoder_out['encoder_padding_mask']:
    encoder_padding_mask = encoder_out['encoder_padding_mask'][0]
else:
    encoder_padding_mask = None
```

### ì˜¤ë¥˜ 4: í‚¤ ì´ë¦„ ë¶ˆì¼ì¹˜

```python
# âŒ ì˜ëª»ëœ ì½”ë“œ
encoder_out = {
    'output': [tensor],  # 'encoder_out'ì´ ì•„ë‹˜!
}

# âœ… ì˜¬ë°”ë¥¸ ì½”ë“œ
encoder_out = {
    'encoder_out': [tensor],  # ì •í™•í•œ í‚¤ ì´ë¦„
}
```

---

## ğŸ“‹ ì²´í¬ë¦¬ìŠ¤íŠ¸

Encoderë¥¼ êµ¬í˜„í•  ë•Œ ë‹¤ìŒì„ í™•ì¸í•˜ì„¸ìš”:

- [ ] `encoder_out`ì€ **List** í˜•íƒœì¸ê°€? (`[tensor]` í˜•ì‹)
- [ ] í…ì„œ ì°¨ì›ì´ **[T, B, D]** (time-first)ì¸ê°€?
- [ ] `encoder_padding_mask`ë„ **List** í˜•íƒœì¸ê°€?
- [ ] Padding mask ì°¨ì›ì´ **[B, T]**ì¸ê°€?
- [ ] í•„ìˆ˜ í‚¤ë“¤ì´ ëª¨ë‘ ìˆëŠ”ê°€?
  - `encoder_out`
  - `encoder_padding_mask`
  - `encoder_embedding` (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ê°€ëŠ¥)
  - `encoder_states` (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ê°€ëŠ¥)
  - `src_tokens` (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ê°€ëŠ¥)
  - `src_lengths` (ë¹ˆ ë¦¬ìŠ¤íŠ¸ ê°€ëŠ¥)

---

## ğŸ” ë””ë²„ê¹… íŒ

### 1. Encoder ì¶œë ¥ í™•ì¸

```python
encoder_out = encoder(src_tokens, src_lengths)

# íƒ€ì… í™•ì¸
print(type(encoder_out['encoder_out']))  # <class 'list'>
print(type(encoder_out['encoder_out'][0]))  # <class 'torch.Tensor'>

# ì°¨ì› í™•ì¸
print(encoder_out['encoder_out'][0].shape)  # [T, B, D]
```

### 2. ë””ì½”ë” ì…ë ¥ í™•ì¸

```python
# ë””ì½”ë”ì— ì „ë‹¬í•˜ê¸° ì „ì— í™•ì¸
encoder_hidden = encoder_out['encoder_out'][0]
print(f"Encoder hidden shape: {encoder_hidden.shape}")  # [T, B, D]

# Padding mask í™•ì¸
if encoder_out['encoder_padding_mask']:
    mask = encoder_out['encoder_padding_mask'][0]
    print(f"Padding mask shape: {mask.shape}")  # [B, T]
```

### 3. ì˜¤ë¥˜ ë©”ì‹œì§€ í•´ì„

```
TypeError: expected Tensor, got list
â†’ encoder_out['encoder_out']ë¥¼ [0]ìœ¼ë¡œ ì¸ë±ì‹±í•˜ì§€ ì•Šì•˜ìŒ

KeyError: 'encoder_out'
â†’ í‚¤ ì´ë¦„ì´ ì˜ëª»ë˜ì—ˆê±°ë‚˜ ë”•ì…”ë„ˆë¦¬ êµ¬ì¡°ê°€ ë‹¤ë¦„

RuntimeError: Expected 3D tensor, got 2D
â†’ ì°¨ì› ìˆœì„œê°€ ì˜ëª»ë˜ì—ˆê±°ë‚˜ transposeê°€ í•„ìš”í•¨
```

---

## ğŸ“š ì°¸ê³ : StreamSpeech ì›ë³¸ ì½”ë“œ

StreamSpeechì˜ Conformer ì¸ì½”ë”ë„ ë™ì¼í•œ í˜•ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤:

```python
# StreamSpeech_analysis/researches/ctc_unity/models/s2t_conformer.py
def _forward(self, src_tokens, src_lengths):
    # ... ì¸ì½”ë”© ë¡œì§ ...
    
    return {
        "encoder_out": [x],  # List of [T, B, C]
        "encoder_padding_mask": (
            [encoder_padding_mask] if encoder_padding_mask.any() else []
        ),
        "encoder_embedding": [],
        "encoder_states": encoder_states,
        "src_tokens": [],
        "src_lengths": [],
    }
```

---

## âœ… ê²°ë¡ 

**í•µì‹¬ ì›ì¹™**:
1. Encoder ì¶œë ¥ì€ **ë°˜ë“œì‹œ List í˜•íƒœ**ë¡œ ë°˜í™˜
2. í…ì„œëŠ” **Time-first** í˜•ì‹ `[T, B, D]`
3. ë””ì½”ë”ì— ì „ë‹¬í•  ë•ŒëŠ” **`[0]`ìœ¼ë¡œ ì¸ë±ì‹±**í•˜ì—¬ í…ì„œ ì¶”ì¶œ
4. Padding maskë„ **List í˜•íƒœ**ì´ë©°, ë¹„ì–´ìˆì„ ìˆ˜ ìˆìŒ

ì´ í˜•ì‹ì„ ì •í™•íˆ ë”°ë¥´ì§€ ì•Šìœ¼ë©´ ë””ì½”ë”ì—ì„œ ì˜¤ë¥˜ê°€ ë°œìƒí•©ë‹ˆë‹¤!

---

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-01-XX  
**ë²„ì „**: 1.0

