# Phase 3: Multi-task Training Implementation âœ…

**Status**: âœ… **COMPLETED**

## ğŸ“‹ Overview

StreamSpeechì˜ Multi-task Learning êµ¬ì¡°ë¥¼ EchoStreamì— ì™„ë²½í•˜ê²Œ í†µí•©í–ˆìŠµë‹ˆë‹¤.

**í•µì‹¬ ê°œì„ ì **:
- **4ê°œ Loss í†µí•©**: L_asr + L_st + L_mt + L_unit
- **Multi-chunk Training**: ëœë¤ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ë¡œ í•™ìŠµ
- **Label Smoothing**: í’ˆì§ˆ í–¥ìƒ
- **Gradient Flow**: ì•ˆì •ì ì¸ í•™ìŠµ

---

## ğŸ¯ Implementation

### 1. Multi-task Criterion

**File**: `training/echostream_criterion.py`

**Loss Components**:

```python
L = L_asr + L_st + L_mt + L_unit

# 1. L_asr: ASR CTC Loss (source text recognition)
#    - Input: Encoder output â†’ ASR CTC Decoder
#    - Target: Source text (e.g., French)
#    - Purpose: ì›ë¬¸ ìŒì„± ì¸ì‹

# 2. L_st: ST CTC Loss (target text translation)
#    - Input: Encoder output â†’ ST CTC Decoder
#    - Target: Target text (e.g., English)
#    - Purpose: ë²ˆì—­ëœ í…ìŠ¤íŠ¸ ìƒì„±

# 3. L_mt: MT Cross-Entropy Loss (text refinement)
#    - Input: ST CTC output â†’ MT Decoder
#    - Target: Target text (refined)
#    - Purpose: ë²ˆì—­ í’ˆì§ˆ í–¥ìƒ

# 4. L_unit: Unit CTC Loss (speech unit generation)
#    - Input: MT output â†’ Unit Decoder
#    - Target: Target speech units
#    - Purpose: ìŒì„± í•©ì„± ì¤€ë¹„
```

**StreamSpeech ì°¸ê³ **:
- `StreamSpeech_analysis/researches/ctc_unity/criterions/speech_to_speech_ctc_asr_st_criterion.py`
- Line 115-200: Multi-task loss computation
- Line 224-232: CTC loss with zero_infinity

---

### 2. Multi-chunk Training

**í•µì‹¬ ì•„ì´ë””ì–´**:
- **ëœë¤ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´**ë¡œ í•™ìŠµ â†’ ë‹¤ì–‘í•œ latencyì— robust
- **StreamSpeech Line 149-168** ì°¸ê³ 

**êµ¬í˜„**:

```python
# Random segment length sampling
segment_choices = [1, 2, 4, 8, 16]  # segments
segment_length = random.choice(segment_choices)

# Model forward with segment_length
model_output = model(
    src_tokens=audio,
    segment_length=segment_length  # â† Multi-chunk!
)
```

**íš¨ê³¼**:
- âœ… **Offline (segment=99999)**: ìµœê³  í’ˆì§ˆ
- âœ… **Online (segment=1~16)**: ë‹¤ì–‘í•œ latency ëŒ€ì‘
- âœ… **Robust**: í•™ìŠµ ì‹œ ë‹¤ì–‘í•œ chunk size ê²½í—˜

---

### 3. Label Smoothing

**ëª©ì **: Overconfidence ë°©ì§€ â†’ ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ

**êµ¬í˜„**:

```python
# Smooth labels
smooth_targets = torch.zeros_like(logits)
smooth_targets.fill_(label_smoothing / (vocab - 1))
smooth_targets.scatter_(1, targets.unsqueeze(1), 1.0 - label_smoothing)

# KL divergence
log_probs = F.log_softmax(logits, dim=-1)
loss = -(smooth_targets * log_probs).sum(dim=-1).mean()
```

**íš¨ê³¼**:
- âœ… **Regularization**: ê³¼ì í•© ë°©ì§€
- âœ… **Calibration**: í™•ë¥  ë¶„í¬ ê°œì„ 

---

## ğŸ§ª Test Results

```bash
$ python training/echostream_criterion.py
```

**Output**:

```
======================================================================
Testing EchoStreamMultiTaskCriterion
======================================================================

1. Testing multi-task loss computation...
   Total loss: 48.6394
   L_asr: 15.7969
   L_st: 15.7323
   L_mt: 9.0060
   L_unit: 8.1043
   âœ… Multi-task loss computed

2. Testing backward pass...
   âœ… Backward pass successful

3. Testing trainer...
   Loss: 47.6648
   Segment length: 2
   âœ… Training step successful

4. Testing multi-chunk sampling...
   Sampled segments: [1, 8, 2, 1, 2, 8, 1, 4, 4, 8]
   âœ… Multi-chunk sampling works

======================================================================
âœ… All EchoStreamMultiTaskCriterion tests passed!
======================================================================
```

---

## ğŸ“Š Comparison: StreamSpeech vs EchoStream

| Feature | StreamSpeech | EchoStream | Improvement |
|---------|--------------|------------|-------------|
| **Encoder** | Conformer (chunk-based) | Emformer (memory-based) | âœ… Efficient |
| **Multi-task Loss** | L_asr + L_st + L_mt + L_unit | L_asr + L_st + L_mt + L_unit | âœ… Same |
| **Multi-chunk** | Random [8, 16, 24, 32] | Random [1, 2, 4, 8, 16] | âœ… More granular |
| **Label Smoothing** | 0.1 | 0.1 | âœ… Same |
| **CTC Loss** | zero_infinity=True | zero_infinity=True | âœ… Same |

---

## ğŸ” Key Insights

### 1. Why Multi-task Learning?

**StreamSpeech ë…¼ë¬¸ í•µì‹¬**:
> "ë²ˆì—­ê³¼ ì •ì±…ì˜ ì´ì¤‘ ê³¼ì œ(double challenges)ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´, ìš°ë¦¬ëŠ” ì›ë¬¸ê³¼ ëª©í‘œ ìŒì„±ì˜ í…ìŠ¤íŠ¸ ì •ë³´ë¥¼ ë„ì…í•˜ì—¬ Simul-S2STë¥¼ ì•ˆë‚´í•œë‹¤."

**íš¨ê³¼**:
1. **L_asr**: ì›ë¬¸ ìŒì„± ì¸ì‹ â†’ Encoderê°€ ìŒì„± íŠ¹ì§•ì„ ì˜ í•™ìŠµ
2. **L_st**: ë²ˆì—­ í…ìŠ¤íŠ¸ ìƒì„± â†’ Encoderê°€ ë²ˆì—­ ì •ë³´ë¥¼ í•™ìŠµ
3. **L_mt**: í…ìŠ¤íŠ¸ ì •ì œ â†’ ë²ˆì—­ í’ˆì§ˆ í–¥ìƒ
4. **L_unit**: ìŒì„± í•©ì„± â†’ ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„± ìƒì„±

**ê²°ê³¼**: ê° taskê°€ ì„œë¡œë¥¼ ë„ì™€ ì „ì²´ í’ˆì§ˆ í–¥ìƒ!

---

### 2. Why Multi-chunk Training?

**ë¬¸ì œ**:
- ê³ ì •ëœ chunk sizeë¡œ í•™ìŠµ â†’ íŠ¹ì • latencyì—ë§Œ ìµœì í™”
- ì‹¤ì œ ì‚¬ìš© ì‹œ ë‹¤ì–‘í•œ latency ìš”êµ¬ â†’ ì„±ëŠ¥ ì €í•˜

**í•´ê²°**:
- ëœë¤ chunk sizeë¡œ í•™ìŠµ â†’ ë‹¤ì–‘í•œ latencyì— robust
- StreamSpeech: [8, 16, 24, 32]
- EchoStream: [1, 2, 4, 8, 16] (ë” ì„¸ë°€í•œ ì œì–´)

**íš¨ê³¼**:
- âœ… **Flexibility**: ë‹¤ì–‘í•œ latency ìš”êµ¬ì‚¬í•­ ëŒ€ì‘
- âœ… **Robustness**: ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ

---

### 3. Why CTC Loss?

**ì¥ì **:
1. **Alignment-free**: ëª…ì‹œì  ì •ë ¬ ë¶ˆí•„ìš”
2. **Parallel**: ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥ â†’ ë¹ ë¥¸ í•™ìŠµ
3. **Monotonic**: ìˆœì°¨ì  ì¶œë ¥ ë³´ì¥ â†’ Streamingì— ì í•©

**ë‹¨ì **:
1. **Independence**: ì¶œë ¥ ê°„ ë…ë¦½ ê°€ì • â†’ í’ˆì§ˆ ì €í•˜

**í•´ê²°**:
- **MT Decoder**: CTC ì¶œë ¥ì„ Autoregressiveë¡œ ì •ì œ â†’ í’ˆì§ˆ í–¥ìƒ
- **Best of both worlds**: CTC (ì†ë„) + AR (í’ˆì§ˆ)

---

## ğŸ’¡ Usage

### Basic Training

```python
from training.echostream_criterion import EchoStreamMultiTaskCriterion, EchoStreamTrainer

# 1. Initialize criterion
criterion = EchoStreamMultiTaskCriterion(
    asr_weight=1.0,
    st_weight=1.0,
    mt_weight=1.0,
    unit_weight=1.0,
    label_smoothing=0.1,
)

# 2. Initialize trainer
trainer = EchoStreamTrainer(
    model=model,
    criterion=criterion,
    optimizer=optimizer,
    multi_chunk=True,
    segment_choices=[1, 2, 4, 8, 16],
)

# 3. Training loop
for batch in dataloader:
    loss, metrics = trainer.train_step(batch)
    
    print(f"Loss: {metrics['loss']:.4f}")
    print(f"  L_asr: {metrics['L_asr']:.4f}")
    print(f"  L_st: {metrics['L_st']:.4f}")
    print(f"  L_mt: {metrics['L_mt']:.4f}")
    print(f"  L_unit: {metrics['L_unit']:.4f}")
    print(f"  Segment: {metrics['segment_length']}")
```

### Custom Loss Weights

```python
# Emphasize translation quality
criterion = EchoStreamMultiTaskCriterion(
    asr_weight=0.5,  # â† Reduce ASR weight
    st_weight=1.5,   # â† Increase ST weight
    mt_weight=2.0,   # â† Increase MT weight
    unit_weight=1.0,
)
```

### Offline Training (No Multi-chunk)

```python
# For offline S2ST (no latency constraint)
trainer = EchoStreamTrainer(
    model=model,
    criterion=criterion,
    optimizer=optimizer,
    multi_chunk=False,  # â† Disable multi-chunk
)
```

---

## ğŸ¯ Next Steps

âœ… **Phase 3 ì™„ë£Œ!**

**ë‹¤ìŒ ë‹¨ê³„**:
- **Phase 4**: Alignment-based Policy (ASR/ST CTC ê¸°ë°˜ READ/WRITE)
- **Phase 5**: Multi-chunk Training í†µí•© (Emformer + Multi-chunk)
- **Phase 6**: ì „ì²´ Agent í†µí•© ë° í…ŒìŠ¤íŠ¸

---

## ğŸ“š References

1. **StreamSpeech Paper**: "StreamSpeech: Simultaneous Speech-to-Speech Translation with Multi-task Learning"
2. **StreamSpeech Code**: `StreamSpeech_analysis/researches/ctc_unity/criterions/speech_to_speech_ctc_asr_st_criterion.py`
3. **CTC Loss**: Graves et al., "Connectionist Temporal Classification"
4. **Label Smoothing**: Szegedy et al., "Rethinking the Inception Architecture"

---

## ğŸ“ Summary

| Component | Status | Description |
|-----------|--------|-------------|
| **Multi-task Criterion** | âœ… | 4ê°œ loss í†µí•© (ASR, ST, MT, Unit) |
| **Multi-chunk Training** | âœ… | ëœë¤ ì„¸ê·¸ë¨¼íŠ¸ ê¸¸ì´ í•™ìŠµ |
| **Label Smoothing** | âœ… | ì¼ë°˜í™” ì„±ëŠ¥ í–¥ìƒ |
| **Gradient Flow** | âœ… | ì•ˆì •ì ì¸ í•™ìŠµ |
| **Test** | âœ… | ëª¨ë“  í…ŒìŠ¤íŠ¸ í†µê³¼ |

**Phase 3 ì™„ë£Œ! ğŸ‰**

