"""
Word Boundary Detector for EchoStream

StreamSpeech Í∞úÏÑ†:
- StreamSpeech: stride_n Í∏∞Î∞ò Í≥†Ï†ï ÌÜ†ÌÅ∞ ÎåÄÍ∏∞
- EchoStream: Îã®Ïñ¥ Í≤ΩÍ≥Ñ Í∏∞Î∞ò ÎèôÏ†Å Ï∂úÎ†•

Ï∞∏Í≥†: StreamSpeech agent/ctc_decoder.pyÏùò CTC collapse Î°úÏßÅ ÌôúÏö©
"""

import torch
import torch.nn as nn
from typing import Optional, Dict, List, Tuple
import logging

logger = logging.getLogger(__name__)


class CTCCollapser:
    """
    CTC Ï∂úÎ†• ÌõÑÏ≤òÎ¶¨ (StreamSpeech Î°úÏßÅ Ï∞®Ïö©).
    
    Ï∞∏Í≥†: agent/ctc_decoder.py:67-89
    """
    
    def __init__(self, blank_idx=0, pad_idx=1):
        self.blank_idx = blank_idx
        self.pad_idx = pad_idx
    
    def collapse(self, tokens: torch.Tensor) -> Tuple[List[int], List[int]]:
        """
        CTC collapse: blank Ï†úÍ±∞ + Ï§ëÎ≥µ Ï†úÍ±∞.
        
        Args:
            tokens: [T] CTC output tokens
        
        Returns:
            collapsed_tokens: List of unique tokens
            indices: Original indices of collapsed tokens
        """
        _toks = tokens.int().tolist()
        
        # Deduplicate (StreamSpeech Line 69-71)
        deduplicated_toks = [
            (v, i) for i, v in enumerate(_toks) 
            if i == 0 or v != _toks[i - 1]
        ]
        
        # Remove blank and pad (StreamSpeech Line 72-76)
        collapsed = []
        indices = []
        for v, i in deduplicated_toks:
            if v != self.blank_idx and v != self.pad_idx:
                collapsed.append(v)
                indices.append(i)
        
        return collapsed, indices


class WordBoundaryDetector:
    """
    Îã®Ïñ¥ Í≤ΩÍ≥Ñ ÌÉêÏßÄÍ∏∞.
    
    ÌïµÏã¨ Í∞úÏÑ†:
    - StreamSpeech: stride_n ÌÜ†ÌÅ∞ÎßàÎã§ Ï≤¥ÌÅ¨ (Í≥†Ï†ï)
    - EchoStream: Îã®Ïñ¥ ÏôÑÏÑ± Ï¶âÏãú ÌÉêÏßÄ (ÎèôÏ†Å)
    
    Î∞©Î≤ï:
    1. ASR CTCÎ°ú Ïã§ÏãúÍ∞Ñ ÌÖçÏä§Ìä∏ ÏÉùÏÑ±
    2. SentencePiece ‚ñÅ ÌÜ†ÌÅ∞ÏúºÎ°ú Îã®Ïñ¥ Í≤ΩÍ≥Ñ ÌåêÎã®
    3. Îã®Ïñ¥ ÏôÑÏÑ± Ïãú Ï¶âÏãú Î∞òÌôò
    """
    
    def __init__(
        self,
        emformer_encoder: nn.Module,
        asr_ctc_decoder: nn.Module,
        tokenizer,  # SentencePiece tokenizer
        device: str = "cuda",
    ):
        self.encoder = emformer_encoder
        self.asr_ctc = asr_ctc_decoder
        self.tokenizer = tokenizer
        self.device = device
        
        # CTC collapser (StreamSpeech Î°úÏßÅ)
        self.ctc_collapser = CTCCollapser(
            blank_idx=0,
            pad_idx=tokenizer.pad() if hasattr(tokenizer, 'pad') else 1
        )
        
        # State
        self.encoder_cache = {}
        self.partial_word = ""
        self.segment_buffer = []
        
        logger.info("WordBoundaryDetector initialized")
    
    def reset(self):
        """ÏÉÅÌÉú Ï¥àÍ∏∞Ìôî."""
        self.encoder_cache = {}
        self.partial_word = ""
        self.segment_buffer = []
        logger.debug("WordBoundaryDetector reset")
    
    def process_segment(
        self,
        audio_segment: torch.Tensor,  # [T_seg, F]
    ) -> Optional[Dict]:
        """
        ÏÑ∏Í∑∏Î®ºÌä∏ Ï≤òÎ¶¨ Î∞è Îã®Ïñ¥ Í≤ΩÍ≥Ñ ÌÉêÏßÄ.
        
        Args:
            audio_segment: [T_seg, F] audio features
        
        Returns:
            None: Îã®Ïñ¥ ÎØ∏ÏôÑÏÑ±
            Dict: ÏôÑÏÑ±Îêú Îã®Ïñ¥ Ï†ïÎ≥¥
                - word: str
                - encoder_out: torch.Tensor
                - asr_tokens: torch.Tensor
                - start_time: float (ms)
                - end_time: float (ms)
        """
        # 1. Emformer encoding (with cache)
        encoder_out, self.encoder_cache = self.encoder(
            audio_segment.unsqueeze(0).to(self.device),
            cache=self.encoder_cache
        )
        
        # 2. ASR CTC decoding
        asr_logits = self.asr_ctc(encoder_out)  # [B, T, vocab]
        asr_tokens = asr_logits.argmax(dim=-1).squeeze(0)  # [T]
        
        # 3. CTC collapse (StreamSpeech Î°úÏßÅ)
        collapsed_tokens, indices = self.ctc_collapser.collapse(asr_tokens)
        
        if len(collapsed_tokens) == 0:
            # No new tokens
            self.segment_buffer.append({
                'encoder_out': encoder_out,
                'time': len(self.segment_buffer) * 40,  # 40ms per segment
            })
            return None
        
        # 4. Decode to text
        try:
            new_text = self.tokenizer.decode(collapsed_tokens)
        except Exception as e:
            logger.warning(f"Tokenizer decode failed: {e}")
            new_text = ""
        
        # 5. Word boundary check
        if self._is_word_boundary(new_text):
            # Îã®Ïñ¥ ÏôÑÏÑ±!
            word = self.partial_word + new_text.rstrip("‚ñÅ ")
            
            result = {
                'word': word,
                'encoder_out': encoder_out,
                'asr_tokens': torch.tensor(collapsed_tokens, device=self.device),
                'start_time': self.segment_buffer[0]['time'] if self.segment_buffer else 0,
                'end_time': len(self.segment_buffer) * 40,
                'is_complete': True,
            }
            
            # Î≤ÑÌçº Ï¥àÍ∏∞Ìôî
            self.partial_word = ""
            self.segment_buffer = []
            
            logger.debug(f"Word completed: '{word}' ({result['start_time']}-{result['end_time']}ms)")
            
            return result
        else:
            # Îã®Ïñ¥ ÎØ∏ÏôÑÏÑ±
            self.partial_word += new_text
            self.segment_buffer.append({
                'encoder_out': encoder_out,
                'time': len(self.segment_buffer) * 40,
            })
            
            logger.debug(f"Partial word: '{self.partial_word}'")
            
            return None
    
    def _is_word_boundary(self, text: str) -> bool:
        """
        Îã®Ïñ¥ Í≤ΩÍ≥Ñ ÌåêÎã®.
        
        Ï°∞Í±¥:
        1. SentencePiece ‚ñÅ ÌÜ†ÌÅ∞ (Îã®Ïñ¥ ÏãúÏûë)
        2. Í≥µÎ∞± Î¨∏Ïûê
        3. Íµ¨ÎëêÏ†ê
        
        Returns:
            True: Îã®Ïñ¥ ÏôÑÏÑ±
            False: Îã®Ïñ¥ ÎØ∏ÏôÑÏÑ±
        """
        if not text:
            return False
        
        # SentencePiece word boundary
        if text.endswith("‚ñÅ"):
            return True
        
        # Space
        if text.endswith(" "):
            return True
        
        # Punctuation
        if text.endswith((".", ",", "!", "?", ";", ":")):
            return True
        
        return False
    
    def force_complete(self) -> Optional[Dict]:
        """
        Í∞ïÏ†úÎ°ú ÌòÑÏû¨ partial wordÎ•º ÏôÑÏÑ±.
        
        ÏÇ¨Ïö©: ÏùåÏÑ± ÏûÖÎ†• Ï¢ÖÎ£å Ïãú
        
        Returns:
            None: partial word ÏóÜÏùå
            Dict: Í∞ïÏ†ú ÏôÑÏÑ±Îêú Îã®Ïñ¥
        """
        if not self.partial_word:
            return None
        
        if not self.segment_buffer:
            return None
        
        # ÎßàÏßÄÎßâ encoder output ÏÇ¨Ïö©
        last_segment = self.segment_buffer[-1]
        
        result = {
            'word': self.partial_word,
            'encoder_out': last_segment['encoder_out'],
            'asr_tokens': torch.tensor([], device=self.device),  # Empty
            'start_time': self.segment_buffer[0]['time'],
            'end_time': last_segment['time'],
            'is_complete': True,
            'forced': True,
        }
        
        # Ï¥àÍ∏∞Ìôî
        self.partial_word = ""
        self.segment_buffer = []
        
        logger.info(f"Force completed word: '{result['word']}'")
        
        return result


if __name__ == "__main__":
    print("="*70)
    print("Testing WordBoundaryDetector")
    print("="*70)
    
    # Mock components
    class MockEmformer(nn.Module):
        def forward(self, x, cache=None):
            B, T, F = x.shape
            out = torch.randn(B, T, 256)
            new_cache = {'mock': True}
            return out, new_cache
    
    class MockASRCTC(nn.Module):
        def forward(self, x):
            B, T, D = x.shape
            vocab_size = 6000
            return torch.randn(B, T, vocab_size)
    
    class MockTokenizer:
        def decode(self, tokens):
            # Mock: return some text
            if len(tokens) > 0:
                return "hello‚ñÅ"
            return ""
        
        def pad(self):
            return 1
    
    # Initialize
    encoder = MockEmformer()
    asr_ctc = MockASRCTC()
    tokenizer = MockTokenizer()
    
    detector = WordBoundaryDetector(
        emformer_encoder=encoder,
        asr_ctc_decoder=asr_ctc,
        tokenizer=tokenizer,
        device="cpu"
    )
    
    print("\n1. Testing segment processing...")
    
    # Segment 1: partial word
    segment1 = torch.randn(4, 80)  # 4 frames, 80 features
    result1 = detector.process_segment(segment1)
    print(f"   Segment 1: {result1}")
    
    # Segment 2: word completion
    segment2 = torch.randn(4, 80)
    result2 = detector.process_segment(segment2)
    print(f"   Segment 2: {result2}")
    
    if result2:
        print(f"   ‚úÖ Word detected: '{result2['word']}'")
        print(f"   Time: {result2['start_time']}-{result2['end_time']}ms")
    
    print("\n2. Testing force complete...")
    detector.partial_word = "incomplete"
    detector.segment_buffer = [{'encoder_out': torch.randn(1, 4, 256), 'time': 0}]
    
    forced = detector.force_complete()
    if forced:
        print(f"   ‚úÖ Forced word: '{forced['word']}'")
    
    print("\n3. Testing reset...")
    detector.reset()
    print(f"   Partial word: '{detector.partial_word}'")
    print(f"   Buffer length: {len(detector.segment_buffer)}")
    print("   ‚úÖ Reset successful")
    
    print("\n" + "="*70)
    print("‚úÖ All WordBoundaryDetector tests passed!")
    print("="*70)
    
    print("\nüí° Usage:")
    print("  detector = WordBoundaryDetector(encoder, asr_ctc, tokenizer)")
    print("  ")
    print("  # Process audio segments")
    print("  for segment in audio_stream:")
    print("      result = detector.process_segment(segment)")
    print("      if result:")
    print("          print(f\"Word: {result['word']}\")")
    print("  ")
    print("  # Force complete at end")
    print("  final = detector.force_complete()")

